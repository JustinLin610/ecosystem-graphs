---
- type: model
  name: CodeGeeX
  organization: Tsinghua University
  description: CodeGeeX is an autoregressive language model trained on code
  created_date: 2022-09-20
  url: https://github.com/THUDM/CodeGeeX
  model_card: none
  modality: text; code
  analysis: none
  size: 13B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: THUDM 1536 Ascend 910 (32GB) Cluster
  quality_control: none
  access:
    explanation: Model weights are available but gated via an [[application form]](https://models.aminer.cn/codegeex/download/request)
    value: limited
  license:
    explanation: The license is provided in the [[Github repository]](https://github.com/THUDM/CodeGeeX)
    value: Apache 2.0
  intended_uses: none
  prohibited_uses: none
  monitoring: none
  feedback: none
- type: model
  name: CogView
  organization: Tsinghua University
  description: CogView is a transformer model for text-to-image generation
  created_date:
    explanation: The date the model paper was released
    value: 2021-05-26
  url: https://arxiv.org/abs/2105.13290
  model_card: none
  modality: text; image
  analysis: ''
  size: 4B parameters (dense)
  dependencies: []
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access:
    explanation: Model checkpoints available from [[Wudao-Wenhui]](https://resource.wudaoai.cn/home?ind=2&name=WuDao%20WenHui&id=1399364355975327744)
    value: open
  license:
    explanation: "The license is provided in the [[Github repository]](https://github.com/THUDM/CogView)\n"
    value: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: CogView 2
  organization: Tsinghua University
  description: CogView 2 is a hierarchical transformer for text-to-image generation
  created_date:
    explanation: The date the model paper was released
    value: 2022-04-28
  url: https://arxiv.org/abs/2204.14217
  model_card: none
  modality: text; image
  analysis: ''
  size: 6B parameters (dense)
  dependencies: []
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access:
    explanation: The model checkpoints are available for download from [[BAAI]](https://model.baai.ac.cn/model-detail/100041)
    value: open
  license:
    explanation: "The license is provided in the [[Github repository]](https://github.com/THUDM/CogView2)\n"
    value: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: CogVideo
  organization: Tsinghua University
  description: CogVideo is a transformer model for text-to-video generation
  created_date:
    explanation: The date the model paper was released
    value: 2022-05-29
  url: https://arxiv.org/abs/2205.15868
  model_card: none
  modality: text; video
  analysis: ''
  size: unknown
  dependencies: []
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access:
    explanation: Model checkpoints are available for download from https://github.com/THUDM/CogVideo
    value: open
  license:
    explanation: "The license is provided in the [[Github repository]](https://github.com/THUDM/CogVideo)\n"
    value: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: GLM-130B
  organization: Tsinghua University
  description: GLM-130B is a bidirectional language model trained on English and
    Chinese
  created_date:
    explanation: The date the model website was made public
    value: 2022-08-04
  url: https://keg.cs.tsinghua.edu.cn/glm-130b/
  model_card: none
  modality: text; text
  analysis: ''
  size: 130B parameters (dense)
  dependencies:
    - The Pile
    - GLM-130B Chinese corpora
    - P3
    - DeepStruct finetuning dataset
  training_emissions: ''
  training_time: ''
  training_hardware: THUDM 96 DGX-A100 (40G) cluster
  quality_control: ''
  access:
    explanation: Model checkpoints are available from the [[GitHub repository]](https://github.com/THUDM/GLM-130B/blob/main/MODEL_LICENSE)
    value: open
  license:
    explanation: Unique model license. See the [[GitHub repository]](https://github.com/THUDM/GLM-130B/blob/main/MODEL_LICENSE)
    value: GLM-130B License
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: CogVLM
  organization: Zhipu AI, Tsinghua University
  description: CogVLM is a powerful open-source visual language foundation model
  created_date: 2023-11-06
  url: https://arxiv.org/pdf/2311.03079.pdf
  model_card: none
  modality: image, text; text
  analysis: Evaluated on image captioning and visual question answering benchmarks.
  size: 17B parameters (dense)
  dependencies: [Vicuna, CLIP]
  training_emissions: unknown
  training_time: 4096 A100 days
  training_hardware: unknown
  quality_control: none
  access: open
  license:
    explanation: Model license can be found at https://github.com/THUDM/CogVLM/blob/main/MODEL_LICENSE. Code license is under Apache 2.0
    value: custom
  intended_uses: Future multimodal research
  prohibited_uses: none
  monitoring: none
  feedback: none
