---
- type: model
  name: GPT-JT
  organization: Together
  description: ''
  created_date: 2022-11-29
  url: https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai
  model_card: ''
  modality: text; text
  analysis: ''
  size: 6B parameters (dense)
  dependencies: [GPT-J, P3, NaturalInstructions-v2]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: GPT-NeoXT-Chat-Base
  organization: Together
  description: ''
  created_date: 2023-03-10
  url: https://www.together.xyz/blog/openchatkit
  model_card: ''
  modality: text; text
  analysis: ''
  size: 20B parameters (dense)
  dependencies: [GPT-NeoX, OIG-43M]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: OpenChatKit moderation model
  organization: Together
  description: ''
  created_date: 2023-03-10
  url: https://www.together.xyz/blog/openchatkit
  model_card: ''
  modality: text; text
  analysis: ''
  size: 6B parameters (dense)
  dependencies: [GPT-JT, OIG-moderation]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: dataset
  name: OIG-43M
  organization: Together, LAION, Ontocord
  description: ''
  created_date: 2023-03-10
  url: https://laion.ai/blog/oig-dataset/
  datasheet: ''
  modality: text
  size: 43M instructions
  sample: []
  analysis: ''
  dependencies: [P3, NaturalInstructions-v2, FLAN dataset]
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: dataset
  name: OIG-moderation
  organization: Together, LAION, Ontocord
  description: ''
  created_date: 2023-03-10
  url: https://laion.ai/blog/oig-dataset/
  datasheet: ''
  modality: text
  size: unknown
  sample: []
  analysis: ''
  dependencies: []
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: dataset
  name: RedPajama-Data
  organization: Together
  description: The RedPajama base dataset is a 1.2 trillion token fully-open dataset
    created by following the recipe described in the LLaMA paper
  created_date: 2022-04-17
  url: https://www.together.xyz/blog/redpajama
  datasheet: https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T
  modality: text
  size: 1.2 trillion tokens
  sample: []
  analysis: ''
  dependencies: [GitHub, Wikipedia]
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: Llama-2-7B-32K-Instruct
  organization: Together
  description: Llama-2-7B-32K-Instruct is an open-source, long-context chat model
    finetuned from Llama-2-7B-32K, over high-quality instruction and chat data.
  created_date: 2023-08-18
  url: https://together.ai/blog/llama-2-7b-32k-instruct
  model_card: https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct
  modality:
    explanation: text; text
    value: text; text
  analysis: Model evaluated over AlpacaEval, Rouge score over BookSum, and accuracy
    over MQA.
  size: 7B parameters (dense)
  dependencies: [BookSum dataset, MQA dataset, Together API, LLaMA 2]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct/discussions

