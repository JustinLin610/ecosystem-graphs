---
- type: model
  name: Prithvi
  organization: IBM
  description: Prithvi is a first-of-its-kind temporal Vision transformer pre-trained
    by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS)
    data. The model adopts a self-supervised encoder developed with a ViT architecture
    and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.
  created_date:
    explanation: The date the model was announced in the [[Adept blog post]](https://www.adept.ai/blog/act-1).
    value: 2023-08-03
  url: https://github.com/NASA-IMPACT/hls-foundation-os
  model_card: https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M
  modality:
    explanation: video; text
    value: text, video; text, video
  analysis: ''
  size: 100M parameters (dense)
  dependencies: [NASA HLS data]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions
- type: application
  name: Watsonx.ai
  organization: IBM
  description: Watsonx.ai is part of the IBM watsonx platform that brings together
    new generative AI capabilities, powered by foundation models and traditional
    machine learning into a powerful studio spanning the AI lifecycle.
  created_date: 2023-09-07
  url: https://www.ibm.com/products/watsonx-ai
  dependencies: [Granite]
  adaptation: ''
  output_space: deployed AI models
  quality_control: ''
  access: limited
  license:
    explanation: License information can be found at https://www.ibm.com/docs/en/watsonxdata/1.0.x?topic=planning-licenses-entitlements
    value: custom
  terms_of_service: https://www.ibm.com/docs/en/watsonx-as-a-service?topic=models-terms-use
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
  monthly_active_users: ''
  user_distribution: ''
  failures: ''
- type: model
  name: Granite
  organization: IBM
  description: Granite is a set of multi-size foundation models that apply generative
    AI to both language and code.
  created_date: 2023-09-28
  url: https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models/
  model_card: none
  modality: text; code, text
  analysis: unknown
  size: 13B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: Training data passed through IBM HAP detector, language model
    designed to remove harmful content. Data also deduplicated and filtered for
    document quality.
  access: limited
  license: ''
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
